\section{Summary}
\label{sec:summary}
To summarize the thesis, we first explained how we trained and evaluated our word2vec model in \cref{sec:training-and-eval-our-word2vec-impl}. We showed that our data preprocessing steps and hyperparameter choices led to the training of a relatively high-quality word embedding model that, among other things, understood syntactic and semantic relationships. We also showed the ability of the model to identify underlying concepts of the English language.

Following, we performed a cluster analysis of word embeddings in \cref{sec:analysis-of-word-embeddings-word-clustering}. We showed that by performing clustering of cluster word embeddings and evaluating the results using internal validation methods, we end up with clusters that intuitively make sense. Additionally, we showed that by clustering word embeddings of distinct word groups, we deepen our understanding of the word embedding manifold. We also used dimensionality reduction methods to visualize results of clustering and showed that the clustering results from the clustering algorithms matched the clusters appearing in the plots.

Next, we investigated the idea of topological polysemy in \cref{sec:analysis-of-embeddings-topological-polysemy}, where we computed the topological polysemy of our word2vec models as well some pre-trained word embedding models. We saw that we were unable to reproduce the results presented in the original paper of topological polysemy, \cite{jakubowski2020topology}. In particular, between the topological polysemy of word embeddings and the true number of word meanings, we got lower correlations and relationships in the opposite direction of the results from \cite{jakubowski2020topology}. Due to the inconsistency in these results, we created a correlation matrix for comparing topological polysemy between our word embedding models and the pre-trained word embeddings. From this, we saw that the fastText model used in the experiments of \cite{jakubowski2020topology} did not correlate well with the rest of the models, signalizing that the word embeddings used in \cite{jakubowski2020topology} can not be compared to other word embeddings. In other words, by applying topological polysemy to other word embeddings than the ones used in \cite{jakubowski2020topology}, we can get unexpected and incorrect results. To deepen our understanding of how the topological polysemy was computed, we conducted two experiments by computing topological polysemy of two custom data sets. The two custom data sets consisted of two spheres intersecting in a single data point, in which topological polysemy should, in theory, be able to identify. The first data set was generated without noise, while the second data set had some noise added to it. The two data sets were created using varying dimensions of the spheres, ranging from 2 to 300. We used the sphere data set with no noise in the first experiment and the sphere data set with noise in the second experiment. From the first experiment, we showed that the measure of topological polysemy was unable to identify the intersection point, but rather a spherical area around the intersection point, for all dimensions of the spheres. In the second experiment, we showed that the measure of topological polysemy was unable to identify both the intersection point and the area around it for small sphere dimensions, $d \in \enclc{2, 3}$, but setting the sphere dimension to 300, we showed that it was possible to identify the intersection point, as it was a significant outlier.

Next, we showed the results of applying the Geometric Anomaly Detection (GAD) algorithm to our word embeddings in \cref{sec:analysis-of-embeddings-geometric-anomaly-detection}, where we compared the results to the number of word meanings, as perceived by topological polysemy and WordNet. Using the results from GAD, we were unable to effectively identify polysemous words. We note, however, that this might be due to a misconfiguration of the hyperparameters.

Following, we used ID estimation methods to compute the estimated local ID of word embeddings in \cref{sec:analysis-of-embeddings-intrinsic-dimension-estimation}, where we showed its relation to the number of word meanings perceived by WordNet, which indicated low correlations.

Finally, we created two supervised models estimating the number of word meanings and predicting whether or not a word is polysemous in \cref{sec:analysis-of-embeddings-supervised-polysemy-prediction}. We used the results from applying topological polysemy, GAD and ID estimation methods to word embeddings to create data used in the supervised models. Furthermore, we used this data to train and evaluate two supervised models for predicting the number of word meanings. We showed a weak correlation between the results from the first supervised model and the number of word meanings and visualized the feature importances in the model. For the second supervised model, we showed the results using confusion matrices, displaying the performance of the model when evaluated to words it has not seen yet, and we showed the feature importances in the model as well. Following, in the next section, we will conclude the thesis.