\section{Conclusion}
\label{sec:conclusion}
To conclude the thesis, we first explained how we trained and evaluated our word2vec model in \cref{sec:training-and-eval-our-word2vec-impl}. We showed that our data preprocessing steps and hyperparameter choices led to the training of a relatively high-quality word embedding model which, among other things, understood syntactic and semantic relationships. We also showed the ability of the model to identify underlying concepts of the English language.

Following, we performed a cluster analysis of word embeddings in \cref{sec:analysis-of-word-embeddings-word-clustering}. We showed that by performing clustering of cluster word embeddings and evaluating the results using internal validation methods, we end up with clusters which intuitively make sense. Additionally, we showed that by clustering word  embeddings of distinct word groups, we deepen our understanding of the word embedding manifold. We also used dimensionality reduction methods to visualize results of clustering, and showed that the clustering results from the clustering algorithms matched the clusters appearing in the plots.

Next, we investigated the application of methods from topological data analysis and intrinsic dimension (ID) estimation on word embeddings in \cref{sec:polysemous-words-prediction}. We showed that by applying topological polysemy to word embeddings models we got some unexpected results, namely that our correlation results suggested a relationship in the opposite direction of the relations showed in the experiments of the original paper introducing topological polysemy. Following, we created a correlation matrix for comparing both our word embedding models and pre-trained word embeddings, and showed that the model used in the experiments of the paper introducing topological polysemy was not correlated with our results. To deepen our understanding of how the topological polysemy score was measured, we conduced two experiments where we computed topological polysemy of two data set consisting of two spheres intersecting in a single data point, where the second data set had some noise added to it as well. The two data sets were created using varying dimensions of the spheres, ranging from 2 to 300. We used the sphere data set with no noise in the first experiment and the sphere data set with noise in the second experiment. From the first experiment, we showed that the measure of topological polysemy was unable to identify the intersection point, but rather a spherical area around the intersection point, for all dimensions of the spheres. In the second experiment, we showed that the measure of topological polysemy was unable to identify both the intersection point and the area around it for small sphere dimensions, $d \in \enclc{2, 3}$, but setting the sphere dimension to 300, we showed that it was possible to identify the intersection point, as it was a significant outlier. Next, we showed the results of applying the Geometric Anomaly Detection (GAD) algorithm to our word embeddings and compared the results to the number of word meanings, as perceived by topological polysemy and WordNet. Using the results from GAD, we were unable to effectively identify polysemous words, but noted that this might be due to a misconfiguration of the hyperparameters. Following, we use ID estimation methods to compute the estimated local ID of word embeddings and showed its relation to the number of word meanings perceived by WordNet.

Finally, we created two supervised models for polysemous words prediction in \cref{sec:analysis-of-embeddings-supervised-polysemy-prediction}. We used the results from applying topological polysemy, GAD and ID estimation methods to word embeddings to create data. Furthermore, we used this data to train and evaluate two supervised models for predicting the number of word meanings. We showed that there was a weak correlation between the results from the first supervised model and the number of word meanings and visualized the importances of the features in the model. For the second supervised model, we showed the results using confusion matrices, displaying the performance of the model when evaluated to words it has not seen yet, and we showed the importances of the features in the model as well.

In the next section, we will discuss our ideas for future work of this thesis.