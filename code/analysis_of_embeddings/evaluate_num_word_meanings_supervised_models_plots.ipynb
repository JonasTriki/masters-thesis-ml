{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-water",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import re\n",
    "from os import makedirs\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from IPython.display import display\n",
    "from skopt.plots import plot_objective\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import skopt\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import xgboost as xgb\n",
    "\n",
    "rng_seed = 399\n",
    "np.random.seed(rng_seed)\n",
    "import persim\n",
    "import joblib\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], \"GPU\")\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != \"GPU\"\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Directory constants\n",
    "root_code_dir = \"..\"\n",
    "output_dir = join(root_code_dir, \"output\")\n",
    "word2vec_training_dir = join(output_dir, \"word2vec_training\")\n",
    "word2vec_ann_indices_dir = join(output_dir, \"word2vec_ann_indices\")\n",
    "word2vec_cluster_analysis_dir = join(output_dir, \"word2vec_cluster_analysis\")\n",
    "output_plots_dir = join(\"output_plots\")\n",
    "makedirs(output_plots_dir, exist_ok=True)\n",
    "\n",
    "# Extend sys path for importing custom Python files\n",
    "import sys\n",
    "\n",
    "sys.path.append(root_code_dir)\n",
    "\n",
    "from topological_data_analysis.topological_polysemy import tps\n",
    "from word_embeddings.word2vec import load_model_training_output\n",
    "from analysis_of_embeddings.estimate_num_meanings_supervised import (\n",
    "    create_classification_labels,\n",
    "    evaluate_regression_model,\n",
    "    evaluate_classification_model,\n",
    "    create_feature_importance_df,\n",
    "    visualize_feature_importances,\n",
    ")\n",
    "from vis_utils import configure_plotting_for_thesis\n",
    "\n",
    "configure_plotting_for_thesis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-outside",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_feature_name_human_readable(feature_name: str) -> str:\n",
    "    \"\"\"\n",
    "    TODO: Docs\n",
    "    \"\"\"\n",
    "    alg_names = [\"tps\", \"gad\", \"estimated_id\"]\n",
    "    human_readable_regexes = [\n",
    "        r\"X_tps_(\\d+)(_pd_(?:max|avg|std)|)\",\n",
    "        r\"X_gad_knn_(\\d+)_(\\d+)_(P_man|P_bnd|P_int)\",\n",
    "        r\"X_estimated_id_(.+)_(\\d+)\",\n",
    "    ]\n",
    "    for alg_name, human_readable_re in zip(alg_names, human_readable_regexes):\n",
    "        re_match = re.match(human_readable_re, feature_name)\n",
    "        if re_match is None:\n",
    "            continue\n",
    "        re_groups = re_match.groups()\n",
    "        if alg_name == \"tps\":\n",
    "            tps_n = re_groups[0]\n",
    "            if re_groups[1] is None:\n",
    "                return fr\"TPS$_{tps_n}\"\n",
    "            else:\n",
    "                tps_pd_type = re_groups[1]\n",
    "                return fr\"TPS{tps_pd_type}_{tps_n}\"\n",
    "        elif alg_name == \"gad\":\n",
    "            inner_annulus_knn, outer_annulus_knn, P_cat = re_groups\n",
    "            P_cat_human = {\n",
    "                \"P_man\": \"manifold\",\n",
    "                \"P_bnd\": \"boundary\",\n",
    "                \"P_int\": \"singular\",\n",
    "            }\n",
    "            return fr\"GAD_{P_cat_human[P_cat]}_{inner_annulus_knn}_{outer_annulus_knn}\"\n",
    "        elif alg_name == \"estimated_id\":\n",
    "            id_estimator_name, num_neighbours = re_groups\n",
    "            id_estimator_human = {\n",
    "                \"lpca\": \"LPCA\",\n",
    "                \"knn\": \"KNN\",\n",
    "                \"twonn\": \"TWO-NN\",\n",
    "                \"mle\": \"MLE\",\n",
    "                \"tle\": \"TLE\",\n",
    "            }\n",
    "            return fr\"ID_{id_estimator_human[id_estimator_name]}_{num_neighbours}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_meaning_train_data = pd.read_csv(\"data/word_meaning_train_data.csv\")\n",
    "word_meaning_test_data = pd.read_csv(\"data/word_meaning_test_data.csv\")\n",
    "word_meaning_semeval_test_data = pd.read_csv(\"data/word_meaning_semeval_test_data.csv\")\n",
    "word_meaning_data_cols = word_meaning_train_data.columns.values\n",
    "word_meaning_data_feature_cols = np.array(\n",
    "    [col for col in word_meaning_data_cols if col.startswith(\"X_\")]\n",
    ")\n",
    "word_meaning_data_feature_cols_human_readable = np.array(\n",
    "    [format_feature_name_human_readable(col) for col in word_meaning_data_feature_cols]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train\")\n",
    "word_meaning_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(word_meaning_train_data[\"y\"], bins=word_meaning_train_data[\"y\"].max())\n",
    "plt.xlabel(\"Label y\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test\")\n",
    "word_meaning_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(word_meaning_test_data[\"y\"], bins=word_meaning_test_data[\"y\"].max())\n",
    "plt.xlabel(\"Label y\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "data_scaler = StandardScaler()\n",
    "data_scaler.fit(word_meaning_train_data[word_meaning_data_feature_cols].values)\n",
    "X_train = data_scaler.transform(word_meaning_train_data[word_meaning_data_feature_cols].values)\n",
    "X_test = data_scaler.transform(word_meaning_test_data[word_meaning_data_feature_cols].values)\n",
    "X_test_semeval = data_scaler.transform(word_meaning_semeval_test_data[word_meaning_data_feature_cols].values)\n",
    "y_train = word_meaning_train_data[\"y\"].values\n",
    "y_test = word_meaning_test_data[\"y\"].values\n",
    "y_test_semeval = word_meaning_semeval_test_data[\"y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4706b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-class labels\n",
    "max_y_multi = np.quantile(y_train, q=0.9)\n",
    "y_train_binary_classes = create_classification_labels(labels=y_train, max_label=1)\n",
    "y_train_multi_class = create_classification_labels(\n",
    "    labels=y_train, max_label=max_y_multi\n",
    ")\n",
    "y_test_binary_classes = create_classification_labels(labels=y_test, max_label=1)\n",
    "y_test_multi_class = create_classification_labels(labels=y_test, max_label=max_y_multi)\n",
    "y_test_semeval_binary_classes = create_classification_labels(\n",
    "    labels=y_test_semeval, max_label=1\n",
    ")\n",
    "y_test_semeval_multi_class = create_classification_labels(\n",
    "    labels=y_test_semeval, max_label=max_y_multi\n",
    ")\n",
    "labels_str = [\n",
    "    str(label + 1) if i < 4 else \"gt_or_eq_5\"\n",
    "    for i, label in enumerate(np.unique(y_train_multi_class))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load output from training word2vec\n",
    "w2v_training_output = load_model_training_output(\n",
    "    model_training_output_dir=join(\n",
    "        word2vec_training_dir, \"word2vec_enwiki_jan_2021_word2phrase\"\n",
    "    ),\n",
    "    model_name=\"word2vec\",\n",
    "    dataset_name=\"enwiki\",\n",
    "    return_normalized_embeddings=True,\n",
    ")\n",
    "last_embedding_weights_normalized = w2v_training_output[\n",
    "    \"last_embedding_weights_normalized\"\n",
    "]\n",
    "words = w2v_training_output[\"words\"]\n",
    "word_to_int = w2v_training_output[\"word_to_int\"]\n",
    "word_counts = w2v_training_output[\"word_counts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SemEval-2010 task 14 words\n",
    "semeval_2010_14_word_senses = joblib.load(\n",
    "    join(\n",
    "        \"..\", \"topological_data_analysis\", \"data\", \"semeval_2010_14_word_senses.joblib\"\n",
    "    )\n",
    ")\n",
    "semeval_target_words = np.array(list(semeval_2010_14_word_senses[\"all\"].keys()))\n",
    "semeval_target_words_in_vocab_filter = [\n",
    "    i for i, word in enumerate(semeval_target_words) if word in word_to_int\n",
    "]\n",
    "semeval_target_words_in_vocab = semeval_target_words[\n",
    "    semeval_target_words_in_vocab_filter\n",
    "]\n",
    "semeval_gs_clusters = np.array(list(semeval_2010_14_word_senses[\"all\"].values()))\n",
    "semeval_gs_clusters_in_vocab = semeval_gs_clusters[semeval_target_words_in_vocab_filter]\n",
    "\n",
    "num_semeval_words = len(semeval_target_words_in_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ed8cf",
   "metadata": {},
   "source": [
    "## Evaluate modeling results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f10d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "estimate_num_meanings_supervised_dir = join(\"data\", \"estimate_num_meanings_supervised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7793d8",
   "metadata": {},
   "source": [
    "### LASSO / Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b0a74",
   "metadata": {},
   "source": [
    "#### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28127ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "lasso_reg = joblib.load(join(estimate_num_meanings_supervised_dir, \"lasso_reg.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d01e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Selected alpha: {lasso_reg.alpha_:.16f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO regression\n",
    "evaluate_regression_model(\n",
    "    model=lasso_reg,\n",
    "    test_sets=[\n",
    "        (\n",
    "            X_train,\n",
    "            y_train,\n",
    "            \"Train\",\n",
    "            \"Predicted number of word meanings\",\n",
    "            \"Synsets in WordNet\",\n",
    "        ),\n",
    "        (\n",
    "            X_test,\n",
    "            y_test,\n",
    "            \"Test\",\n",
    "            \"Predicted number of word meanings\",\n",
    "            \"Synsets in WordNet\",\n",
    "        ),\n",
    "        (\n",
    "            X_test_semeval,\n",
    "            y_test_semeval,\n",
    "            \"SemEval test\",\n",
    "            \"Predicted number of word meanings\",\n",
    "            \"SemEval gold standard\",\n",
    "        ),\n",
    "    ],\n",
    "    show_plot=False,\n",
    "    use_rasterization=True,\n",
    ")\n",
    "\n",
    "# Plot/save\n",
    "save_to_pgf = True\n",
    "plt.tight_layout()\n",
    "if save_to_pgf:\n",
    "    plt.savefig(\n",
    "        join(\n",
    "            output_plots_dir,\n",
    "            \"wme-enwiki-correlation-result.pdf\",\n",
    "        ),\n",
    "        backend=\"pgf\",\n",
    "    )\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d777bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 10 feature importances\n",
    "_, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Sort coefficient by absolute value\n",
    "lasso_reg_coef_abs_sorted_indces = np.argsort(abs(lasso_reg.coef_))[::-1]\n",
    "top_n_importances = 10\n",
    "top_n_importances_indices = lasso_reg_coef_abs_sorted_indces[:top_n_importances]\n",
    "\n",
    "# Plot horizontal barplot\n",
    "y_pos = np.arange(top_n_importances)\n",
    "ax.barh(y=y_pos, width=lasso_reg.coef_[top_n_importances_indices], color=\"b\")\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(\n",
    "    word_meaning_data_feature_cols_human_readable[top_n_importances_indices]\n",
    ")\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Feature importance\")\n",
    "\n",
    "# Plot/save\n",
    "save_to_pgf = True\n",
    "plt.tight_layout()\n",
    "if save_to_pgf:\n",
    "    plt.savefig(\n",
    "        join(\n",
    "            output_plots_dir,\n",
    "            \"wme-enwiki-top-10-feature-importances.pdf\",\n",
    "        ),\n",
    "        backend=\"pgf\",\n",
    "    )\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 10 feature importances\n",
    "_, axes = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "ax_chars = \"abc\"\n",
    "\n",
    "top_n_importances = 10\n",
    "feature_alg_names = [\"TPS\", \"GAD\", \"ID estimator\"]\n",
    "feature_alg_names_start = [\"X_tps\", \"X_gad\", \"X_estimated_id\"]\n",
    "for ax, ax_char, alg_name, alg_names_start in zip(\n",
    "    axes, ax_chars, feature_alg_names, feature_alg_names_start\n",
    "):\n",
    "    # Filter algorithm columns\n",
    "    alg_filter = [\n",
    "        i\n",
    "        for i, feature_col in enumerate(word_meaning_data_feature_cols)\n",
    "        if feature_col.startswith(alg_names_start)\n",
    "    ]\n",
    "    alg_coeffs = lasso_reg.coef_[alg_filter]\n",
    "\n",
    "    # Sort coefficient by absolute value\n",
    "    lasso_reg_coef_abs_sorted_indces = np.argsort(abs(alg_coeffs))[::-1]\n",
    "    top_n_importances_indices = lasso_reg_coef_abs_sorted_indces[:top_n_importances]\n",
    "\n",
    "    # Plot horizontal barplot\n",
    "    y_pos = np.arange(top_n_importances)\n",
    "    ax.barh(y=y_pos, width=alg_coeffs[top_n_importances_indices], color=\"b\")\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(\n",
    "        word_meaning_data_feature_cols_human_readable[alg_filter][\n",
    "            top_n_importances_indices\n",
    "        ]\n",
    "    )\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(\"Feature importance\")\n",
    "    ax.set_title(f\"({ax_char}) {alg_name} features\")\n",
    "\n",
    "# Plot/save\n",
    "save_to_pgf = True\n",
    "plt.tight_layout()\n",
    "if save_to_pgf:\n",
    "    plt.savefig(\n",
    "        join(\n",
    "            output_plots_dir,\n",
    "            \"wme-enwiki-top-10-feature-importances-tps-gad-estimated-ids.pdf\",\n",
    "        ),\n",
    "        backend=\"pgf\",\n",
    "    )\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a58a856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_feature_importances(\n",
    "    feature_importances=create_feature_importance_df(\n",
    "        feature_names=word_meaning_data_feature_cols,\n",
    "        feature_importances=np.abs(lasso_reg.coef_),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of zero features: {sum(lasso_reg.coef_ == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f71f32",
   "metadata": {},
   "source": [
    "#### Logistic regression with L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ec733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "binary_logistic_reg = joblib.load(\n",
    "    join(estimate_num_meanings_supervised_dir, \"binary_logistic_reg.joblib\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f43ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Selected alpha: {(1 / binary_logistic_reg.C_[0]):.16f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ea453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification\n",
    "evaluate_classification_model(\n",
    "    model=binary_logistic_reg,\n",
    "    test_sets=[\n",
    "        (\n",
    "            X_train,\n",
    "            y_train_binary_classes,\n",
    "            \"Train\",\n",
    "            \"Predicted number of word meanings\",\n",
    "            \"Synsets in WordNet\",\n",
    "        ),\n",
    "        (\n",
    "            X_test,\n",
    "            y_test_binary_classes,\n",
    "            \"Test\",\n",
    "            \"Predicted number of word meanings\",\n",
    "            \"Synsets in WordNet\",\n",
    "        ),\n",
    "    ],\n",
    "    cm_ticklabels=[\"1 word meaning\", \">1 word meanings\"],\n",
    "    show_plot=False,\n",
    ")\n",
    "\n",
    "# Plot/save\n",
    "save_to_pgf = True\n",
    "plt.tight_layout()\n",
    "if save_to_pgf:\n",
    "    plt.savefig(\n",
    "        join(\n",
    "            output_plots_dir,\n",
    "            \"bwme-enwiki-confusion-matrices.pdf\",\n",
    "        ),\n",
    "        backend=\"pgf\",\n",
    "    )\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d715b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 10 feature importances\n",
    "_, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Sort coefficient by absolute value\n",
    "binary_log_reg_coef_abs_sorted_indces = np.argsort(abs(binary_logistic_reg.coef_[0]))[\n",
    "    ::-1\n",
    "]\n",
    "top_n_importances = 10\n",
    "top_n_importances_indices = binary_log_reg_coef_abs_sorted_indces[:top_n_importances]\n",
    "\n",
    "# Plot horizontal barplot\n",
    "y_pos = np.arange(top_n_importances)\n",
    "ax.barh(\n",
    "    y=y_pos, width=binary_logistic_reg.coef_[0][top_n_importances_indices], color=\"b\"\n",
    ")\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(\n",
    "    word_meaning_data_feature_cols_human_readable[top_n_importances_indices]\n",
    ")\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Feature importance\")\n",
    "\n",
    "# Plot/save\n",
    "save_to_pgf = True\n",
    "plt.tight_layout()\n",
    "if save_to_pgf:\n",
    "    plt.savefig(\n",
    "        join(\n",
    "            output_plots_dir,\n",
    "            \"bwme-enwiki-top-10-feature-importances.pdf\",\n",
    "        ),\n",
    "        backend=\"pgf\",\n",
    "    )\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 10 feature importances\n",
    "_, axes = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "ax_chars = \"abc\"\n",
    "\n",
    "top_n_importances = 10\n",
    "feature_alg_names = [\"TPS\", \"GAD\", \"ID estimator\"]\n",
    "feature_alg_names_start = [\"X_tps\", \"X_gad\", \"X_estimated_id\"]\n",
    "for ax, ax_char, alg_name, alg_names_start in zip(\n",
    "    axes, ax_chars, feature_alg_names, feature_alg_names_start\n",
    "):\n",
    "    # Filter algorithm columns\n",
    "    alg_filter = [\n",
    "        i\n",
    "        for i, feature_col in enumerate(word_meaning_data_feature_cols)\n",
    "        if feature_col.startswith(alg_names_start)\n",
    "    ]\n",
    "    alg_coeffs = binary_logistic_reg.coef_[0][alg_filter]\n",
    "\n",
    "    # Sort coefficient by absolute value\n",
    "    binary_log_reg_coef_abs_sorted_indces = np.argsort(abs(alg_coeffs))[::-1]\n",
    "    top_n_importances_indices = binary_log_reg_coef_abs_sorted_indces[\n",
    "        :top_n_importances\n",
    "    ]\n",
    "\n",
    "    # Plot horizontal barplot\n",
    "    y_pos = np.arange(top_n_importances)\n",
    "    ax.barh(y=y_pos, width=alg_coeffs[top_n_importances_indices], color=\"b\")\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(\n",
    "        word_meaning_data_feature_cols_human_readable[alg_filter][\n",
    "            top_n_importances_indices\n",
    "        ]\n",
    "    )\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(\"Feature importance\")\n",
    "    ax.set_title(f\"({ax_char}) {alg_name} features\")\n",
    "\n",
    "# Plot/save\n",
    "save_to_pgf = True\n",
    "plt.tight_layout()\n",
    "if save_to_pgf:\n",
    "    plt.savefig(\n",
    "        join(\n",
    "            output_plots_dir,\n",
    "            \"bwme-enwiki-top-10-feature-importances-tps-gad-estimated-ids.pdf\",\n",
    "        ),\n",
    "        backend=\"pgf\",\n",
    "    )\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef0fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_feature_importances(\n",
    "    feature_importances=create_feature_importance_df(\n",
    "        feature_names=word_meaning_data_feature_cols,\n",
    "        feature_importances=np.abs(binary_logistic_reg.coef_[0]),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of zero features: {sum(binary_logistic_reg.coef_[0] == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b16fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ca7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20af6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6234c691",
   "metadata": {},
   "source": [
    "# Old cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f84be04",
   "metadata": {},
   "source": [
    "#### Multinomial logistic regression with L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 1 / multi_class_logistic_reg.C_\n",
    "print(f\"Selected alphas: {alphas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2700e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for label_str, coeffs in zip(labels_str, multi_class_logistic_reg.coef_):\n",
    "    sorted_feature_weights_indices = np.argsort(np.abs(coeffs))[::-1]\n",
    "    df_dict[f\"feature_{label_str}\"] = word_meaning_data_feature_cols[\n",
    "        sorted_feature_weights_indices\n",
    "    ]\n",
    "    df_dict[f\"weight_{label_str}\"] = coeffs[sorted_feature_weights_indices]\n",
    "\n",
    "sorted_features_df = pd.DataFrame(df_dict)\n",
    "visualize_feature_importances(feature_importances=sorted_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ab061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi classification\n",
    "evaluate_classification_model(\n",
    "    model=multi_class_logistic_reg,\n",
    "    test_sets=[\n",
    "        (\n",
    "            X_train,\n",
    "            y_train_multi_class,\n",
    "            \"Train\",\n",
    "            \"Pred number of synsets\",\n",
    "            \"Synsets in Wordnet\",\n",
    "        ),\n",
    "        (\n",
    "            X_test,\n",
    "            y_test_multi_class,\n",
    "            \"Test\",\n",
    "            \"Pred number of synsets\",\n",
    "            \"Synsets in Wordnet\",\n",
    "        ),\n",
    "    ],\n",
    "    cm_ticklabels=labels_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a386d",
   "metadata": {},
   "source": [
    "### XGBoost regression and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdef3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "xgb_reg = joblib.load(join(estimate_num_meanings_supervised_dir, \"xgb_reg.joblib\"))\n",
    "xgb_reg_model = xgb_reg.best_estimator_\n",
    "xgb_binary_classification = joblib.load(\n",
    "    join(estimate_num_meanings_supervised_dir, \"xgb_binary_classification.joblib\")\n",
    ")\n",
    "xgb_binary_classification_model = xgb_binary_classification.best_estimator_\n",
    "# xgb_multi_classification = joblib.load(join(estimate_num_meanings_supervised_dir, \"xgb_multi_classification.joblib\"))\n",
    "# xgb_multi_classification_model = xgb_multi_classification.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd29428e",
   "metadata": {},
   "source": [
    "#### XGBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bayesian optimization results\n",
    "plot_objective(xgb_reg.optimizer_results_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53fb07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_feature_importances(\n",
    "    feature_importances=create_feature_importance_df(\n",
    "        feature_names=word_meaning_data_feature_cols,\n",
    "        feature_importances=xgb_reg_model.feature_importances_,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8d5b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_regression_model(\n",
    "    model=xgb_reg_model,\n",
    "    test_sets=[\n",
    "        (X_train, y_train, \"Train\", \"Pred number of synsets\", \"Synsets in Wordnet\"),\n",
    "        (X_test, y_test, \"Test\", \"Pred number of synsets\", \"Synsets in Wordnet\"),\n",
    "        (\n",
    "            X_test_semeval,\n",
    "            y_test_semeval,\n",
    "            \"SemEval GS\",\n",
    "            \"Pred number of meanings\",\n",
    "            \"Clusters in GS\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c5395a",
   "metadata": {},
   "source": [
    "#### XGBoost binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bayesian optimization results\n",
    "plot_objective(xgb_binary_classification.optimizer_results_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00071e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_feature_importances(\n",
    "    feature_importances=create_feature_importance_df(\n",
    "        feature_names=word_meaning_data_feature_cols,\n",
    "        feature_importances=xgb_binary_classification_model.feature_importances_,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f79eed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Binary classification\n",
    "evaluate_classification_model(\n",
    "    model=xgb_binary_classification_model,\n",
    "    test_sets=[\n",
    "        (\n",
    "            X_train,\n",
    "            y_train_binary_classes,\n",
    "            \"Train\",\n",
    "            \"Pred number of synsets\",\n",
    "            \"Synsets in Wordnet\",\n",
    "        ),\n",
    "        (\n",
    "            X_test,\n",
    "            y_test_binary_classes,\n",
    "            \"Test\",\n",
    "            \"Pred number of synsets\",\n",
    "            \"Synsets in Wordnet\",\n",
    "        ),\n",
    "    ],\n",
    "    cm_ticklabels=[\"1 meaning\", \"2 or more meanings\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc3d12",
   "metadata": {},
   "source": [
    "#### XGBoost multiclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41acf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bayesian optimization results\n",
    "plot_objective(xgb_multi_classification.optimizer_results_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a114658",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_feature_importances(\n",
    "    feature_importances=create_feature_importance_df(\n",
    "        feature_names=word_meaning_data_feature_cols,\n",
    "        feature_importances=xgb_multi_classification_model.feature_importances_,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi classification\n",
    "evaluate_classification_model(\n",
    "    model=xgb_multi_classification_model,\n",
    "    test_sets=[\n",
    "        (\n",
    "            X_train,\n",
    "            y_train_multi_class,\n",
    "            \"Train\",\n",
    "            \"Pred number of synsets\",\n",
    "            \"Synsets in Wordnet\",\n",
    "        ),\n",
    "        (\n",
    "            X_test,\n",
    "            y_test_multi_class,\n",
    "            \"Test\",\n",
    "            \"Pred number of synsets\",\n",
    "            \"Synsets in Wordnet\",\n",
    "        ),\n",
    "    ],\n",
    "    cm_ticklabels=labels_str,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
