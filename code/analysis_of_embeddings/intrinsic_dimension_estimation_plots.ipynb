{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec13424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "rng_seed = 399\n",
    "np.random.seed(rng_seed)\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.offsetbox import AnnotationBbox, TextArea\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import gudhi as gd\n",
    "from gudhi.wasserstein import wasserstein_distance\n",
    "\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.corpus import wordnet as wn\n",
    "import annoy\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import plotly.offline as pyo\n",
    "\n",
    "pyo.init_notebook_mode()\n",
    "import plotly.express as px\n",
    "\n",
    "# Directory constants\n",
    "analysis_of_embeddings_data_dir = \"data\"\n",
    "root_code_dir = \"..\"\n",
    "output_dir = join(root_code_dir, \"output\")\n",
    "word2vec_training_dir = join(output_dir, \"word2vec_training\")\n",
    "word2vec_ann_indices_dir = join(output_dir, \"word2vec_ann_indices\")\n",
    "word2vec_cluster_analysis_dir = join(output_dir, \"word2vec_cluster_analysis\")\n",
    "tps_experimentation_dir = join(output_dir, \"topological_polysemy_experimentation\")\n",
    "wme_word2vec_enwiki_dir = join(\"raw_data\", \"wme_word2vec_enwiki\")\n",
    "output_plots_dir = join(\"output_plots\")\n",
    "makedirs(output_plots_dir, exist_ok=True)\n",
    "\n",
    "# Extend sys path for importing custom Python files\n",
    "import sys\n",
    "\n",
    "sys.path.append(root_code_dir)\n",
    "\n",
    "from utils import (\n",
    "    get_model_checkpoint_filepaths,\n",
    "    pairwise_cosine_distances,\n",
    "    words_to_vectors,\n",
    ")\n",
    "from word_embeddings.word2vec import load_model_training_output\n",
    "from vis_utils import plot_word_vectors, configure_plotting_for_thesis\n",
    "from topological_data_analysis.geometric_anomaly_detection import compute_gad\n",
    "from analysis_utils import transform_word_embeddings\n",
    "\n",
    "configure_plotting_for_thesis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed2e0cb",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41269bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load output from training word2vec\n",
    "w2v_training_output = load_model_training_output(\n",
    "    model_training_output_dir=join(\n",
    "        word2vec_training_dir, \"word2vec_enwiki_jan_2021_word2phrase\"\n",
    "    ),\n",
    "    model_name=\"word2vec\",\n",
    "    dataset_name=\"enwiki\",\n",
    ")\n",
    "last_embedding_weights = w2v_training_output[\"last_embedding_weights\"]\n",
    "words = w2v_training_output[\"words\"]\n",
    "word_to_int = w2v_training_output[\"word_to_int\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_words_to_num_meanings = False\n",
    "if compute_words_to_num_meanings:\n",
    "    print(\"Finding words in vocabulary with #Wordnet synsets > 0\")\n",
    "    words_to_num_meanings = {}\n",
    "    for word in tqdm(words):\n",
    "        num_synsets = len(wn.synsets(word))\n",
    "        if num_synsets > 0:\n",
    "            words_to_num_meanings[word] = num_synsets\n",
    "    joblib.dump(\n",
    "        words_to_num_meanings,\n",
    "        join(analysis_of_embeddings_data_dir, \"word2vec-enwiki-wordnet-dict.joblib\"),\n",
    "    )\n",
    "else:\n",
    "    words_to_num_meanings = joblib.load(\n",
    "        join(analysis_of_embeddings_data_dir, \"word2vec-enwiki-wordnet-dict.joblib\")\n",
    "    )\n",
    "data_words = np.array(list(words_to_num_meanings.keys()))\n",
    "data_words_to_full_vocab_ints = np.array([word_to_int[word] for word in data_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e047dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ID estimation result from supervised task\n",
    "knn_size = 200\n",
    "id_estimator_keys = [\"lpca\", \"twonn\", \"tle\"]\n",
    "id_estimator_to_human_readable = {\"lpca\": \"lPCA\", \"twonn\": \"TwoNN\", \"tle\": \"TLE\"}\n",
    "id_estimators = {}\n",
    "for id_estimator_key in id_estimator_keys:\n",
    "    id_estimators[id_estimator_key] = np.load(\n",
    "        join(\n",
    "            wme_word2vec_enwiki_dir,\n",
    "            \"estimated_ids\",\n",
    "            f\"{id_estimator_key}_{knn_size}.npy\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c136c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot estimated ID vs. number of word meanings\n",
    "_, axes = plt.subplots(ncols=3, figsize=(5 * 3, 5))\n",
    "ax_chars = \"abc\"\n",
    "\n",
    "for ax, ax_char, id_estimator_key in zip(axes.ravel(), ax_chars, id_estimator_keys):\n",
    "\n",
    "    estimated_id_num_synsets_corr, _ = pearsonr(\n",
    "        x=id_estimators[id_estimator_key],\n",
    "        y=list(words_to_num_meanings.values()),\n",
    "    )\n",
    "    ax_scatter_handle = ax.scatter(\n",
    "        x=id_estimators[id_estimator_key],\n",
    "        y=list(words_to_num_meanings.values()),\n",
    "        s=10,\n",
    "        label=f\"Correlation: {estimated_id_num_synsets_corr:.3f}\",\n",
    "    )\n",
    "    ax.set_xlabel(\"Estimated ID\")\n",
    "    ax.set_ylabel(\"Synsets in WordNet\")\n",
    "    ax.set_title(\n",
    "        f\"({ax_char}) Estimated ID w/{id_estimator_to_human_readable[id_estimator_key]}\"\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax_scatter_handle.set_rasterized(True)\n",
    "\n",
    "# Plot/save\n",
    "save_to_pgf = True\n",
    "plt.tight_layout()\n",
    "if save_to_pgf:\n",
    "    plt.savefig(\n",
    "        join(\n",
    "            output_plots_dir,\n",
    "            \"intrinsic-dimension-estimation-vs-wordnet-synsets.pdf\",\n",
    "        ),\n",
    "        backend=\"pgf\",\n",
    "    )\n",
    "else:\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
