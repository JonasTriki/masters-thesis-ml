{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "import joblib\n",
    "import numpy as np\n",
    "rng_seed = 399\n",
    "np.random.seed(rng_seed)\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.cluster import (KMeans, SpectralClustering, AgglomerativeClustering,\n",
    "                             MiniBatchKMeans)\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# Clustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster\n",
    "\n",
    "from umap import UMAP\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "# Directory constants\n",
    "analysis_of_embeddings_dir = \"..\"\n",
    "analysis_of_embeddings_data_dir = join(analysis_of_embeddings_dir, \"data\")\n",
    "analysis_of_embeddings_custom_data_dir = join(analysis_of_embeddings_dir, \"custom_data\")\n",
    "root_code_dir = join(analysis_of_embeddings_dir, \"..\")\n",
    "output_dir = join(root_code_dir, \"output\")\n",
    "word2vec_training_dir = join(output_dir, \"word2vec_training\")\n",
    "word2vec_cluster_analysis_dir = join(output_dir, \"word2vec_cluster_analysis\")\n",
    "\n",
    "# Extend sys path for importing custom Python files\n",
    "import sys\n",
    "sys.path.extend([analysis_of_embeddings_dir, root_code_dir])\n",
    "\n",
    "from utils import get_model_checkpoint_filepaths, pairwise_cosine_distances\n",
    "from analysis_utils import (plot_cluster_metric_scores, transform_word_embeddings,\n",
    "                            words_in_clusters, plot_cluster_sizes, inspect_word_clusters,\n",
    "                            load_word_cluster_group_words, visualize_word_cluster_groups)\n",
    "from cluster_analysis_metrics import (silhouette_score_metric, davies_bouldin_score_metric,\n",
    "                                      s_dbw_score_metric, sd_score_metric, cdbw_score_metric)\n",
    "from cluster_analysis_utils import (cluster_analysis, visualize_cluster_analysis_result,\n",
    "                                    plot_word_embeddings_clustered)\n",
    "from word_embeddings.word2vec import load_model_training_output\n",
    "from vis_utils import plot_word_vectors\n",
    "from topological_data_analysis.tda_utils import plot_persistence_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load output from training word2vec\n",
    "w2v_training_output = load_model_training_output(\n",
    "    model_training_output_dir=join(word2vec_training_dir, \"word2vec_enwiki_sept_2020_word2phrase\"),\n",
    "    model_name=\"word2vec\",\n",
    "    dataset_name=\"enwiki\",\n",
    ")\n",
    "last_embedding_weights = w2v_training_output[\"last_embedding_weights\"]\n",
    "words = w2v_training_output[\"words\"]\n",
    "word_to_int = w2v_training_output[\"word_to_int\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict vocabulary size for analysis\n",
    "vocab_size = 10000\n",
    "vocabulary = list(range(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "should_pred_cluster_labels = True\n",
    "#n_clusters = [2, 3, 4, 5, 10, 50, 100, 150, 200, 300, 400, 500, 750, 1000, 1500, 2000, 3000, 4000, 5000, 6000, 7000, 8000]\n",
    "n_clusters = [2, 3, 4, 5]\n",
    "eval_metrics = [\n",
    "    (\"silhouette_score\", silhouette_score_metric),\n",
    "    (\"sd_score\", sd_score_metric),\n",
    "    (\"s_dbw_score\", s_dbw_score_metric),\n",
    "]\n",
    "eval_metrics_grid=[\n",
    "    eval_metrics,\n",
    "    eval_metrics,\n",
    "    eval_metrics\n",
    "]\n",
    "eval_metrics_params={\n",
    "    \"silhouette_score\": {\"metric\": \"precomputed\"},\n",
    "}\n",
    "clusterers=[\n",
    "    (\"Agglomerative clustering\", AgglomerativeClustering),\n",
    "    (\"K-means clustering\", KMeans),\n",
    "    (\"Spectral clustering\", SpectralClustering)\n",
    "]\n",
    "hyperparameter_grids=[\n",
    "    {\n",
    "        \"n_clusters\": n_clusters,\n",
    "        \"affinity\": [\"precomputed\"],\n",
    "        \"linkage\": [\"single\", \"average\", \"complete\"],\n",
    "    },\n",
    "    {\"n_clusters\": n_clusters, \"random_state\": [rng_seed]},\n",
    "    {\"n_clusters\": n_clusters, \"random_state\": [rng_seed]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_pred_cluster_labels:\n",
    "    cluster_analysis_result, word_vecs, pairwise_word_distances = cluster_analysis(\n",
    "        clusterers=clusterers,\n",
    "        hyperparameter_grids=hyperparameter_grids,\n",
    "        eval_metrics_grid=eval_metrics_grid,\n",
    "        eval_metrics_params=eval_metrics_params,\n",
    "        word_embeddings=last_embedding_weights,\n",
    "        words_vocabulary=vocabulary,\n",
    "        word_to_int=word_to_int,\n",
    "        compute_pairwise_word_distances=True,\n",
    "        return_word_vectors=True,\n",
    "        save_result_to_disk=True,\n",
    "        output_dir=word2vec_cluster_analysis_dir,\n",
    "        model_name=\"word2vec\",\n",
    "        dataset_name=\"enwiki\",\n",
    "        output_filepath_suffix=\"cluster_labels\",\n",
    "    )\n",
    "else:\n",
    "    cluster_analysis_result, word_vecs, pairwise_word_distances = joblib.load(\n",
    "        join(word2vec_cluster_analysis_dir, \"word2vec-enwiki-cluster_labels.joblib\")\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
