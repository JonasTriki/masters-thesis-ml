{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "import joblib\n",
    "import numpy as np\n",
    "rng_seed = 399\n",
    "np.random.seed(rng_seed)\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster\n",
    "\n",
    "from umap import UMAP\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "# Directory constants\n",
    "analysis_of_embeddings_dir = \"..\"\n",
    "analysis_of_embeddings_data_dir = join(analysis_of_embeddings_dir, \"data\")\n",
    "analysis_of_embeddings_custom_data_dir = join(analysis_of_embeddings_dir, \"custom_data\")\n",
    "root_code_dir = join(analysis_of_embeddings_dir, \"..\")\n",
    "output_dir = join(root_code_dir, \"output\")\n",
    "word2vec_training_dir = join(output_dir, \"word2vec_training\")\n",
    "word2vec_cluster_analysis_dir = join(output_dir, \"word2vec_cluster_analysis\")\n",
    "\n",
    "# Extend sys path for importing custom Python files\n",
    "import sys\n",
    "sys.path.extend([analysis_of_embeddings_dir, root_code_dir])\n",
    "\n",
    "from utils import get_model_checkpoint_filepaths, pairwise_cosine_distances\n",
    "from analysis_utils import (agglomerative_clustering,\n",
    "                            agglomerative_cluster_hyperparameter_search, plot_cluster_metric_scores,\n",
    "                            words_in_clusters, plot_cluster_sizes, inspect_word_clusters,\n",
    "                            load_word_cluster_group_words, visualize_word_cluster_groups)\n",
    "from word_embeddings.eval_utils import plot_word_vectors\n",
    "from word_embeddings.word2vec import load_model_training_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load output from training word2vec\n",
    "w2v_training_output = load_model_training_output(\n",
    "    model_training_output_dir=join(word2vec_training_dir, \"word2vec_enwiki_sept_2020_word2phrase\"),\n",
    "    model_name=\"word2vec\",\n",
    "    dataset_name=\"enwiki\",\n",
    ")\n",
    "last_embedding_weights = w2v_training_output[\"last_embedding_weights\"]\n",
    "words = w2v_training_output[\"words\"]\n",
    "word_to_int = w2v_training_output[\"word_to_int\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict vocabulary size for analysis\n",
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Precompute cosine distance matrix\n",
    "word_embeddings_to_precompute = last_embedding_weights[:vocab_size]\n",
    "word_embeddings_distances = pairwise_cosine_distances(word_embeddings_to_precompute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform agglomerative clustering\n",
    "agglomerative_clusterings = agglomerative_clustering(\n",
    "    word_embeddings_pairwise_dists=word_embeddings_distances,\n",
    "    linkages=[\"complete\", \"average\", \"single\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdbw import CDbw\n",
    "from s_dbw import S_Dbw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerative_cluster_hyperparameter_search(\n",
    "    cluster_numbers: list,\n",
    "    linkages: list,\n",
    "    agglomerative_clusterings: dict,\n",
    "    word_embeddings: np.ndarray,\n",
    "    word_embeddings_pairwise_dists: np.ndarray,\n",
    "    output_dir: str,\n",
    "    model_name: str,\n",
    "    dataset_name: str,\n",
    "    output_filepath_suffix: str,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Searches for the best set of hyperparameters using agglomerative\n",
    "    clustering and various internal cluster metrics:\n",
    "    - Silhouette Coefficient\n",
    "    - S_Dbw validity index\n",
    "    - CDbw validity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cluster_numbers : list\n",
    "        List of cluster numbers to evaluate.\n",
    "    linkages : list\n",
    "        List of linkages to evaluate\n",
    "    agglomerative_clusterings : dict\n",
    "        Dictionary containing result from `agglomerative_clustering`\n",
    "        function.\n",
    "    word_embeddings : np.ndarray\n",
    "        Word embeddings to perform clustering on\n",
    "    word_embeddings_pairwise_dists : np.ndarray\n",
    "        Numpy matrix containing pairwise distances between word embeddings\n",
    "    output_dir : str\n",
    "        Output directory\n",
    "    model_name : str\n",
    "        Name of the model\n",
    "    dataset_name : str\n",
    "        Name of the dataset the model was trained on\n",
    "    output_filepath_suffix : str\n",
    "        Output filepath suffix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        Dictionary containing cluster labels and metric scores\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Perform clustering\n",
    "    clustering_result = {}\n",
    "    print(f\"-- Fitting and predicting cluster labels for agglomerative clustering --\")\n",
    "    for linkage in linkages:\n",
    "        print(f\"Linkage: {linkage}\")\n",
    "\n",
    "        cluster_labels = []\n",
    "        cluster_metrics = {\n",
    "            \"silhouette_coeff\": {\n",
    "                \"name\": \"Silhouette Coefficient\",\n",
    "                \"scores\": [],\n",
    "                \"best_score_idx\": -1,\n",
    "            },\n",
    "            \"s_dbw\": {\n",
    "                \"name\": \"S_Dbw validity index\",\n",
    "                \"scores\": [],\n",
    "                \"best_score_idx\": -1,\n",
    "            },\n",
    "            \"cdbw\": {\n",
    "                \"name\": \"CDbw validity index\",\n",
    "                \"scores\": [],\n",
    "                \"best_score_idx\": -1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        for k in tqdm(cluster_numbers):\n",
    "            linkage_matrix = agglomerative_clusterings[linkage][\"linkage_matrix\"]\n",
    "            cluster_labels_pred = fcluster(Z=linkage_matrix, criterion=\"maxclust\", t=k) - 1\n",
    "            cluster_labels.append(cluster_labels_pred)\n",
    "\n",
    "            # Compute metric scores\n",
    "            silhouette_coeff_score = silhouette_score(\n",
    "                X=word_embeddings_pairwise_dists,\n",
    "                labels=cluster_labels_pred,\n",
    "                metric=\"precomputed\",\n",
    "            )\n",
    "            s_dbw_score = S_Dbw(\n",
    "                X=word_embeddings, labels=cluster_labels_pred, metric=\"cosine\"\n",
    "            )\n",
    "            cdbw_score = CDbw(\n",
    "                X=word_embeddings, labels=cluster_labels_pred, metric=\"cosine\", s=3\n",
    "            )\n",
    "            print(silhouette_coeff_score, s_dbw_score, cdbw_score)\n",
    "\n",
    "            # Append metric scores\n",
    "            cluster_metrics[\"silhouette_coeff\"][\"scores\"].append(silhouette_coeff_score)\n",
    "            cluster_metrics[\"s_dbw\"][\"scores\"].append(s_dbw_score)\n",
    "            cluster_metrics[\"cdbw\"][\"scores\"].append(cdbw_score)\n",
    "\n",
    "        # Find set score index for each metric\n",
    "        cluster_metrics[\"silhouette_coeff\"][\"best_score_idx\"] = np.argmax(\n",
    "            cluster_metrics[\"silhouette_coeff\"][\"scores\"]\n",
    "        )\n",
    "        cluster_metrics[\"s_dbw\"][\"best_score_idx\"] = np.argmin(\n",
    "            cluster_metrics[\"s_dbw\"][\"scores\"]\n",
    "        )\n",
    "        cluster_metrics[\"cdbw\"][\"best_score_idx\"] = np.argmax(\n",
    "            cluster_metrics[\"cdbw\"][\"scores\"]\n",
    "        )\n",
    "        clustering_result[linkage] = {\n",
    "            \"cluster_labels\": cluster_labels,\n",
    "            \"cluster_metrics\": cluster_metrics,\n",
    "        }\n",
    "\n",
    "    # Save result to output dir\n",
    "    save_cluster_result_to_disk(\n",
    "        clustering_result, output_dir, model_name, dataset_name, output_filepath_suffix\n",
    "    )\n",
    "\n",
    "    return clustering_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_pred_cluster_labels = True\n",
    "ks = [2, 3, 4, 5, 10, 50, 100, 150, 200, 300, 400, 500, 750, 1000, 1500, 2000, 3000, 4000, 5000, 6000, 7000, 8000]\n",
    "if should_pred_cluster_labels:\n",
    "    pred_cluster_labels = agglomerative_cluster_hyperparameter_search(\n",
    "        cluster_numbers=ks,\n",
    "        linkages=list(agglomerative_clusterings.keys()),\n",
    "        agglomerative_clusterings=agglomerative_clusterings,\n",
    "        word_embeddings=word_embeddings_to_precompute,\n",
    "        word_embeddings_pairwise_dists=word_embeddings_distances,\n",
    "        output_dir=word2vec_cluster_analysis_dir,\n",
    "        model_name=\"word2vec\",\n",
    "        dataset_name=\"enwiki\",\n",
    "        output_filepath_suffix=\"agglomerative_labels\",\n",
    "    )\n",
    "else:\n",
    "    pred_cluster_labels = joblib.load(\n",
    "        join(word2vec_cluster_analysis_dir, \"word2vec-enwiki-agglomerative_labels.joblib\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for linkage in agglomerative_clusterings.keys():\n",
    "    print(f\"Linkage: {linkage}\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    plot_cluster_metric_scores(\n",
    "        metric_scores=pred_cluster_labels[linkage][\"metric_scores\"],\n",
    "        hyperparameters=[{\"n_clusters\": k} for k in ks],\n",
    "        best_score_idx=pred_cluster_labels[linkage][\"best_cluster_labels_idx\"],\n",
    "        metric_name=\"Silhouette\",\n",
    "        ax=ax\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: single linkage clustering does not seem to yield any good results looking at the silhouette score (lots of negative scores) and we will discard it from the further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in at 3000-6000 clusters, discarding single linkage clustering.\n",
    "should_pred_cluster_labels_zoomed = False\n",
    "start_zoom_cluster_num = 3000\n",
    "end_zoom_cluster_num = 6000\n",
    "ks_zoomed = np.arange(start_zoom_cluster_num, end_zoom_cluster_num + 1) # np.linspace(3000, 6000, num=100, dtype=int)\n",
    "if should_pred_cluster_labels_zoomed:\n",
    "    pred_cluster_labels_zoomed = agglomerative_cluster_hyperparameter_search(\n",
    "        cluster_numbers=ks_zoomed,\n",
    "        linkages=[\"complete\", \"average\"],\n",
    "        agglomerative_clusterings=agglomerative_clusterings,\n",
    "        word_embeddings_pairwise_dists=word_embeddings_distances,\n",
    "        output_dir=word2vec_cluster_analysis_dir,\n",
    "        model_name=\"word2vec\",\n",
    "        dataset_name=\"enwiki\",\n",
    "        output_filepath_suffix=\"agglomerative_labels_zoomed\",\n",
    "    )\n",
    "else:\n",
    "    pred_cluster_labels_zoomed = joblib.load(\n",
    "        join(word2vec_cluster_analysis_dir, \"word2vec-enwiki-agglomerative_labels_zoomed.joblib\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_cluster_labels = {}\n",
    "for linkage in [\"complete\", \"average\"]:\n",
    "    print(f\"Linkage: {linkage}\")\n",
    "    silhouette_scores = pred_cluster_labels_zoomed[linkage][\"metric_scores\"]\n",
    "    best_cluster_labels_idx = pred_cluster_labels_zoomed[linkage][\"best_cluster_labels_idx\"]\n",
    "    \n",
    "    best_num_clusters = ks_zoomed[best_cluster_labels_idx]\n",
    "    print(f\"Best number of clusters: {best_num_clusters}\")\n",
    "    \n",
    "    best_cluster_labels[linkage] = pred_cluster_labels_zoomed[linkage][\"cluster_labels\"][best_cluster_labels_idx]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    plot_cluster_metric_scores(\n",
    "        hyperparameters=[{\"n_clusters\": k} for k in ks_zoomed],\n",
    "        metric_scores=silhouette_scores,\n",
    "        best_score_idx=best_cluster_labels_idx,\n",
    "        metric_name=\"Silhouette\",\n",
    "        scatter=False,\n",
    "        set_xticks=False,\n",
    "        ax=ax,\n",
    "        xlabel=\"Cluster number\",\n",
    "        xrange=ks_zoomed\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete linkage clustering yields the highest silhouette score. For this reason, we choose this linkage for the cluster analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_cluster_labels = best_cluster_labels[\"complete\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot cluster sizes\n",
    "most_common_cluster_sizes = plot_cluster_sizes(chosen_cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect word clusters\n",
    "inspect_word_clusters(\n",
    "    cluster_labels=chosen_cluster_labels,\n",
    "    words=words[:vocab_size],\n",
    "    min_cluster_size=5,\n",
    "    most_common_cluster_sizes=most_common_cluster_sizes,\n",
    "    num_words_in_clusters_print=10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
