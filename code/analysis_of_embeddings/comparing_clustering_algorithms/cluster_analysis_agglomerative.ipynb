{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "import joblib\n",
    "import numpy as np\n",
    "rng_seed = 399\n",
    "np.random.seed(rng_seed)\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster\n",
    "\n",
    "from umap import UMAP\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "# Directory constants\n",
    "analysis_of_embeddings_dir = \"..\"\n",
    "analysis_of_embeddings_data_dir = join(analysis_of_embeddings_dir, \"data\")\n",
    "analysis_of_embeddings_custom_data_dir = join(analysis_of_embeddings_dir, \"custom_data\")\n",
    "root_code_dir = join(analysis_of_embeddings_dir, \"..\")\n",
    "output_dir = join(root_code_dir, \"output\")\n",
    "word2vec_training_dir = join(output_dir, \"word2vec_training\")\n",
    "word2vec_cluster_analysis_dir = join(output_dir, \"word2vec_cluster_analysis\")\n",
    "\n",
    "# Extend sys path for importing custom Python files\n",
    "import sys\n",
    "sys.path.extend([analysis_of_embeddings_dir, root_code_dir])\n",
    "\n",
    "from utils import get_model_checkpoint_filepaths, pairwise_cosine_distances\n",
    "from analysis_utils import (agglomerative_clustering,\n",
    "                            agglomerative_cluster_hyperparameter_search, plot_cluster_metric_scores,\n",
    "                            words_in_clusters, plot_cluster_sizes, inspect_word_clusters,\n",
    "                            load_word_cluster_group_words, visualize_word_cluster_groups)\n",
    "from word_embeddings.eval_utils import plot_word_vectors\n",
    "from word_embeddings.word2vec import load_model_training_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load output from training word2vec\n",
    "w2v_training_output = load_model_training_output(\n",
    "    model_training_output_dir=join(word2vec_training_dir, \"word2vec_enwiki_sept_2020_word2phrase\"),\n",
    "    model_name=\"word2vec\",\n",
    "    dataset_name=\"enwiki\",\n",
    ")\n",
    "last_embedding_weights = w2v_training_output[\"last_embedding_weights\"]\n",
    "words = w2v_training_output[\"words\"]\n",
    "word_to_int = w2v_training_output[\"word_to_int\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict vocabulary size for analysis\n",
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Precompute cosine distance matrix\n",
    "word_embeddings_to_precompute = last_embedding_weights[:vocab_size]\n",
    "word_embeddings_distances = pairwise_cosine_distances(word_embeddings_to_precompute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform agglomerative clustering\n",
    "agglomerative_clusterings = agglomerative_clustering(\n",
    "    word_embeddings_pairwise_dists=word_embeddings_distances,\n",
    "    linkages=[\"complete\", \"average\", \"single\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_pred_cluster_labels = False\n",
    "ks = [2, 3, 4, 5, 10, 50, 100, 150, 200, 300, 400, 500, 750, 1000, 1500, 2000, 3000, 4000, 5000, 6000, 7000, 8000]\n",
    "if should_pred_cluster_labels:\n",
    "    pred_cluster_labels = agglomerative_cluster_hyperparameter_search(\n",
    "        cluster_numbers=ks,\n",
    "        linkages=list(agglomerative_clusterings.keys()),\n",
    "        agglomerative_clusterings=agglomerative_clusterings,\n",
    "        word_embeddings_pairwise_dists=word_embeddings_distances,\n",
    "        output_dir=word2vec_cluster_analysis_dir,\n",
    "        model_name=\"word2vec\",\n",
    "        dataset_name=\"enwiki\",\n",
    "        output_filepath_suffix=\"agglomerative_labels\",\n",
    "    )\n",
    "else:\n",
    "    pred_cluster_labels = joblib.load(\n",
    "        join(word2vec_cluster_analysis_dir, \"word2vec-enwiki-agglomerative_labels.joblib\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for linkage in agglomerative_clusterings.keys():\n",
    "    print(f\"Linkage: {linkage}\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    plot_cluster_metric_scores(\n",
    "        metric_scores=pred_cluster_labels[linkage][\"metric_scores\"],\n",
    "        hyperparameters=[{\"n_clusters\": k} for k in ks],\n",
    "        best_score_idx=pred_cluster_labels[linkage][\"best_cluster_labels_idx\"],\n",
    "        metric_name=\"Silhouette\",\n",
    "        ax=ax\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: single linkage clustering does not seem to yield any good results looking at the silhouette score (lots of negative scores) and we will discard it from the further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in at 3000-6000 clusters, discarding single linkage clustering.\n",
    "should_pred_cluster_labels_zoomed = False\n",
    "start_zoom_cluster_num = 3000\n",
    "end_zoom_cluster_num = 6000\n",
    "ks_zoomed = np.arange(start_zoom_cluster_num, end_zoom_cluster_num + 1) # np.linspace(3000, 6000, num=100, dtype=int)\n",
    "if should_pred_cluster_labels_zoomed:\n",
    "    pred_cluster_labels_zoomed = agglomerative_cluster_hyperparameter_search(\n",
    "        cluster_numbers=ks_zoomed,\n",
    "        linkages=[\"complete\", \"average\"],\n",
    "        agglomerative_clusterings=agglomerative_clusterings,\n",
    "        word_embeddings_pairwise_dists=word_embeddings_distances,\n",
    "        output_dir=word2vec_cluster_analysis_dir,\n",
    "        model_name=\"word2vec\",\n",
    "        dataset_name=\"enwiki\",\n",
    "        output_filepath_suffix=\"agglomerative_labels_zoomed\",\n",
    "    )\n",
    "else:\n",
    "    pred_cluster_labels_zoomed = joblib.load(\n",
    "        join(word2vec_cluster_analysis_dir, \"word2vec-enwiki-agglomerative_labels_zoomed.joblib\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_cluster_labels = {}\n",
    "for linkage in [\"complete\", \"average\"]:\n",
    "    print(f\"Linkage: {linkage}\")\n",
    "    silhouette_scores = pred_cluster_labels_zoomed[linkage][\"metric_scores\"]\n",
    "    best_cluster_labels_idx = pred_cluster_labels_zoomed[linkage][\"best_cluster_labels_idx\"]\n",
    "    \n",
    "    best_num_clusters = ks_zoomed[best_cluster_labels_idx]\n",
    "    print(f\"Best number of clusters: {best_num_clusters}\")\n",
    "    \n",
    "    best_cluster_labels[linkage] = pred_cluster_labels_zoomed[linkage][\"cluster_labels\"][best_cluster_labels_idx]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    plot_cluster_metric_scores(\n",
    "        hyperparameters=[{\"n_clusters\": k} for k in ks_zoomed],\n",
    "        metric_scores=silhouette_scores,\n",
    "        best_score_idx=best_cluster_labels_idx,\n",
    "        metric_name=\"Silhouette\",\n",
    "        scatter=False,\n",
    "        set_xticks=False,\n",
    "        ax=ax,\n",
    "        xlabel=\"Cluster number\",\n",
    "        xrange=ks_zoomed\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete linkage clustering yields the highest silhouette score. For this reason, we choose this linkage for the cluster analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_cluster_labels = best_cluster_labels[\"complete\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot cluster sizes\n",
    "most_common_cluster_sizes = plot_cluster_sizes(chosen_cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect word clusters\n",
    "inspect_word_clusters(\n",
    "    cluster_labels=chosen_cluster_labels,\n",
    "    words=words[:vocab_size],\n",
    "    min_cluster_size=5,\n",
    "    most_common_cluster_sizes=most_common_cluster_sizes,\n",
    "    num_words_in_clusters_print=10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
