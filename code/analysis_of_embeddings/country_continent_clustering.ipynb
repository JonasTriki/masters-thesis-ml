{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "rng_seed = 399\n",
    "np.random.seed(rng_seed)\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "import requests\n",
    "\n",
    "from utils import get_model_checkpoint_filepaths\n",
    "from analysis_utils import words_in_clusters, plot_silhouette_scores\n",
    "from text_preprocessing_utils import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last word embeddings from training\n",
    "checkpoint_filepaths_dict = get_model_checkpoint_filepaths(\n",
    "    output_dir=\"../output/word2vec_training/31-Oct-2020_14-45-28\",\n",
    "    model_name=\"word2vec\",\n",
    "    dataset_name=\"enwiki\",\n",
    ")\n",
    "last_embedding_weights_filepath = checkpoint_filepaths_dict[\"intermediate_embedding_weight_filepaths\"][-1]\n",
    "last_embedding_weights = np.load(last_embedding_weights_filepath, mmap_mode=\"r\").astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words and create word to int lookup dict\n",
    "with open(checkpoint_filepaths_dict[\"train_words_filepath\"], \"r\") as file:\n",
    "    words = np.array(file.read().split(\"\\n\"))\n",
    "word_to_int = {word: i for i, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load country-capital data\n",
    "# country_capital_df = pd.read_csv(\"data/country_capitals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    TODO: Docs\n",
    "    \"\"\"\n",
    "    remove_paranthesis_re = re.compile(\"^(.+?)\\(.*?\\)(.*?)$\")\n",
    "    name_no_paranthesis_results = re.findall(remove_paranthesis_re, name)\n",
    "    if len(name_no_paranthesis_results) > 0:\n",
    "        name = \"\".join(name_no_paranthesis_results[0]).strip()\n",
    "    name = \" \".join(preprocess_text(name)).replace(\" \", \"_\")\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame with countries, capitals, regions, lat and lng\n",
    "req = requests.get(\"https://restcountries.eu/rest/v2\")\n",
    "req_json = req.json()\n",
    "country_capital_df_dict = {\n",
    "    \"country\": [],\n",
    "    \"capital\": [],\n",
    "    \"region\": [],\n",
    "    \"latitude\": [],\n",
    "    \"longitude\": [],\n",
    "}\n",
    "for country in req_json:\n",
    "    \n",
    "    # Check if country has capital\n",
    "    if country[\"capital\"] == \"\":\n",
    "        continue\n",
    "        \n",
    "    # Add to dict\n",
    "    country_capital_df_dict[\"country\"].append(preprocess_name(country[\"name\"]))\n",
    "    country_capital_df_dict[\"capital\"].append(preprocess_name(country[\"capital\"]))\n",
    "    country_capital_df_dict[\"region\"].append(country[\"region\"])\n",
    "    country_capital_df_dict[\"latitude\"].append(country[\"latlng\"][0])\n",
    "    country_capital_df_dict[\"longitude\"].append(country[\"latlng\"][1])\n",
    "\n",
    "country_capital_df = pd.DataFrame(country_capital_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_capital_pairs_in_vocab = country_capital_df[[\"country\", \"capital\"]].isin(words).apply(all, axis=1)\n",
    "country_capital_in_vocab_df = country_capital_df[country_capital_pairs_in_vocab]\n",
    "print(f\"Total {len(country_capital_df)} country/capital pairs, of them {len(country_capital_in_vocab_df)} in vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    country_capital_df,\n",
    "    x=\"longitude\",\n",
    "    y=\"latitude\",\n",
    "    title=\"Capitals of countries of the world in lat/lng coordinates\",\n",
    "    labels={\"longitude\": \"Longitude\", \"latitude\": \"Latitude\"},\n",
    "    color=\"region\",\n",
    "    hover_data=[\"country\", \"capital\"]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word vectors of country capitals\n",
    "countries = country_capital_in_vocab_df[\"country\"].values\n",
    "country_capitals = country_capital_in_vocab_df[\"capital\"].values\n",
    "country_capital_word_vecs = np.zeros((len(country_capitals), last_embedding_weights.shape[1]))\n",
    "for i, capital in enumerate(country_capitals):\n",
    "    country_capital_word_vecs[i] = last_embedding_weights[word_to_int[capital]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cluster labels\n",
    "country_capital_cluster_sizes = [5, 6, 7]\n",
    "country_capital_cluster_labels = []\n",
    "for k in country_capital_cluster_sizes:\n",
    "    cluster_labels = KMeans(n_clusters=k).fit_predict(country_capital_word_vecs)\n",
    "    country_capital_cluster_labels.append(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 2D UMAP embedding\n",
    "country_capital_word_vecs_umap_2d = UMAP(\n",
    "    n_components=2,\n",
    "    #n_neighbors=20,\n",
    "    #min_dist=0.15,\n",
    "    metric=\"cosine\",\n",
    "    random_state=rng_seed\n",
    ").fit_transform(country_capital_word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize embedding\n",
    "for cluster_size, cluster_labels in zip(country_capital_cluster_sizes, country_capital_cluster_labels):\n",
    "    \n",
    "    # Plot\n",
    "    fig = px.scatter(\n",
    "        x=country_capital_word_vecs_umap_2d[:, 0],\n",
    "        y=country_capital_word_vecs_umap_2d[:, 1],\n",
    "        title=f\"Capitals of countries of the world in UMAP coordinates with {cluster_size} clusters\",\n",
    "        labels={\"x\": \"UMAP 1\", \"y\": \"UMAP 2\"},\n",
    "        color=cluster_labels,\n",
    "        hover_data={\"country\": countries, \"capital\": country_capitals}\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    cluster_words, _ = words_in_clusters(cluster_labels, countries)\n",
    "    print(f\"Countries in clusters\")\n",
    "    for word_cluster in cluster_words:\n",
    "        print(word_cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
