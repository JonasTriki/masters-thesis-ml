{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "\n",
    "rng_seed = 399\n",
    "np.random.seed(rng_seed)\n",
    "import persim\n",
    "import joblib\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegressionCV\n",
    "from sklearn.preprocessing import minmax_scale, RobustScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], \"GPU\")\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != \"GPU\"\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Directory constants\n",
    "root_code_dir = \"..\"\n",
    "output_dir = join(root_code_dir, \"output\")\n",
    "word2vec_training_dir = join(output_dir, \"word2vec_training\")\n",
    "word2vec_ann_indices_dir = join(output_dir, \"word2vec_ann_indices\")\n",
    "word2vec_cluster_analysis_dir = join(output_dir, \"word2vec_cluster_analysis\")\n",
    "\n",
    "# Extend sys path for importing custom Python files\n",
    "import sys\n",
    "\n",
    "sys.path.append(root_code_dir)\n",
    "\n",
    "from topological_data_analysis.topological_polysemy import tps\n",
    "from word_embeddings.word2vec import load_model_training_output\n",
    "from analysis_of_embeddings.estimate_num_meanings_supervised import (\n",
    "    plot_pred_vs_true_labels,\n",
    "    create_multi_class_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-outside",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_meaning_train_data = pd.read_csv(\"data/word_meaning_train_data.csv\")\n",
    "word_meaning_test_data = pd.read_csv(\"data/word_meaning_test_data.csv\")\n",
    "word_meaning_semeval_test_data = pd.read_csv(\"data/word_meaning_semeval_test_data.csv\")\n",
    "word_meaning_data_cols = word_meaning_train_data.columns.values\n",
    "word_meaning_data_feature_cols = np.array(\n",
    "    [col for col in word_meaning_data_cols if col.startswith(\"X_\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train\")\n",
    "word_meaning_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(word_meaning_train_data[\"y\"], bins=word_meaning_train_data[\"y\"].max())\n",
    "plt.xlabel(\"Label y\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test\")\n",
    "word_meaning_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(word_meaning_test_data[\"y\"], bins=word_meaning_test_data[\"y\"].max())\n",
    "plt.xlabel(\"Label y\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X_train = minmax_scale(word_meaning_train_data[word_meaning_data_feature_cols].values)\n",
    "X_test = minmax_scale(word_meaning_test_data[word_meaning_data_feature_cols].values)\n",
    "X_test_semeval = minmax_scale(\n",
    "    word_meaning_semeval_test_data[word_meaning_data_feature_cols].values\n",
    ")\n",
    "y_train = word_meaning_train_data[\"y\"].values\n",
    "y_test = word_meaning_test_data[\"y\"].values\n",
    "y_test_semeval = word_meaning_semeval_test_data[\"y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load output from training word2vec\n",
    "w2v_training_output = load_model_training_output(\n",
    "    model_training_output_dir=join(\n",
    "        word2vec_training_dir, \"word2vec_enwiki_jan_2021_word2phrase\"\n",
    "    ),\n",
    "    model_name=\"word2vec\",\n",
    "    dataset_name=\"enwiki\",\n",
    "    return_normalized_embeddings=True,\n",
    ")\n",
    "last_embedding_weights_normalized = w2v_training_output[\n",
    "    \"last_embedding_weights_normalized\"\n",
    "]\n",
    "words = w2v_training_output[\"words\"]\n",
    "word_to_int = w2v_training_output[\"word_to_int\"]\n",
    "word_counts = w2v_training_output[\"word_counts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SemEval-2010 task 14 words\n",
    "semeval_2010_14_word_senses = joblib.load(\n",
    "    join(\n",
    "        \"..\", \"topological_data_analysis\", \"data\", \"semeval_2010_14_word_senses.joblib\"\n",
    "    )\n",
    ")\n",
    "semeval_target_words = np.array(list(semeval_2010_14_word_senses[\"all\"].keys()))\n",
    "semeval_target_words_in_vocab_filter = [\n",
    "    i for i, word in enumerate(semeval_target_words) if word in word_to_int\n",
    "]\n",
    "semeval_target_words_in_vocab = semeval_target_words[\n",
    "    semeval_target_words_in_vocab_filter\n",
    "]\n",
    "semeval_gs_clusters = np.array(list(semeval_2010_14_word_senses[\"all\"].values()))\n",
    "semeval_gs_clusters_in_vocab = semeval_gs_clusters[semeval_target_words_in_vocab_filter]\n",
    "\n",
    "num_semeval_words = len(semeval_target_words_in_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-papua",
   "metadata": {},
   "source": [
    "## Do modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-personality",
   "metadata": {},
   "source": [
    "### Lasso regression with K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training result\n",
    "lasso_cv = joblib.load(\"data/lasso_reg.joblib\")\n",
    "print(f\"Selected alpha: {lasso_cv.alpha_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-thanksgiving",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_feature_weights_indices = np.argsort(np.abs(lasso_cv.coef_))[::-1]\n",
    "sorted_features_arr = np.array(\n",
    "    list(\n",
    "        zip(\n",
    "            word_meaning_data_feature_cols[sorted_feature_weights_indices],\n",
    "            lasso_cv.coef_[sorted_feature_weights_indices],\n",
    "        )\n",
    "    )\n",
    ")\n",
    "sorted_features_df = pd.DataFrame(\n",
    "    {\"feature\": sorted_features_arr[:, 0], \"weight\": sorted_features_arr[:, 1]}\n",
    ")\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(sorted_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-sampling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = lasso_cv.predict(X_train)\n",
    "plot_pred_vs_true_labels(\n",
    "    y_pred, y_train, xlabel=\"Pred number of synsets\", ylabel=\"Synsets in Wordnet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-situation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred_test = lasso_cv.predict(X_test)\n",
    "plot_pred_vs_true_labels(\n",
    "    y_pred_test, y_test, xlabel=\"Pred number of meanings\", ylabel=\"Clusters in GS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_semeval = lasso_cv.predict(X_test_semeval)\n",
    "plot_pred_vs_true_labels(\n",
    "    y_pred_test_semeval,\n",
    "    y_test_semeval,\n",
    "    xlabel=\"Pred number of meanings\",\n",
    "    ylabel=\"Clusters in GS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-documentary",
   "metadata": {},
   "source": [
    "### Multi-class logistic regression with L1-penalty, finding optimal alpha with K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-class labels\n",
    "max_y_multi = np.quantile(y_train, q=0.9)\n",
    "y_train_multi_class = create_multi_class_labels(labels=y_train, max_label=max_y_multi)\n",
    "y_test_multi_class = create_multi_class_labels(labels=y_test, max_label=max_y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load result from training\n",
    "log_reg_cv = joblib.load(\"data/log_reg_cv.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / log_reg_cv.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_str = [\n",
    "    str(label + 1) if i < 4 else \">= 5\" for i, label in enumerate(log_reg_cv.classes_)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for label_str, coeffs in zip(labels_str, log_reg_cv.coef_):\n",
    "    sorted_feature_weights_indices = np.argsort(np.abs(coeffs))[::-1]\n",
    "    df_dict[f\"feature_{label_str}\"] = word_meaning_data_feature_cols[\n",
    "        sorted_feature_weights_indices\n",
    "    ]\n",
    "    df_dict[f\"weight_{label_str}\"] = coeffs[sorted_feature_weights_indices]\n",
    "\n",
    "sorted_features_df = pd.DataFrame(df_dict)\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(sorted_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-antique",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = log_reg_cv.predict(X_train)\n",
    "cm = confusion_matrix(y_train_multi_class, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    cmap=\"YlGnBu\",\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    annot_kws={\"size\": 16},\n",
    "    square=True,\n",
    "    xticklabels=labels_str,\n",
    "    yticklabels=labels_str,\n",
    ")\n",
    "plt.title(\"Word meaning prediction vs. true\")\n",
    "plt.xlabel(\"Predicted No. word meanings\")\n",
    "plt.ylabel(\"True No. word meanings\")\n",
    "plt.show()\n",
    "\n",
    "pred_f1_score = f1_score(y_train_multi_class, y_pred, average=\"weighted\")\n",
    "print(f\"F1-score: {pred_f1_score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
